FILE: Sources/llminty/IgnoreMatcher.swift

import Foundation
/// Minimal gitignore-like engine with globs (* ? **), dir-trailing '/', root-anchored '/' and negation '!'
/// Evaluation order: built-ins first (exclude bias), then user's .mintyignore (last match wins)
struct IgnoreMatcher {
struct Pattern {
let negated: Bool
let dirOnly: Bool
let anchorRoot: Bool
let raw: String
let segments: [String] // split on '/'
}
private let ordered: [Pattern]
init(builtInPatterns: [String], userFileText: String) throws {
var list: [Pattern] = []
for p in builtInPatterns { if let pat = Self.parse(line: p) { list.append(pat) } }
for line in userFileText.components(separatedBy: .newlines) {
if let pat = Self.parse(line: line) { list.append(pat) }
}
self.ordered = list
}
// MARK: - Parser
private static func parse(line: String) -> Pattern? { ... }
// MARK: - Eval
func isIgnored(_ relativePath: String, isDirectory: Bool) -> Bool { ... }
private static func match(pattern p: Pattern, pathSegments: [String]) -> Bool { ... }
// Segment matcher for '*' and '?'
private static func matchSegment(_ pat: String, _ txt: String) -> Bool { ... }
// '**' matches zero or more segments. '*' matches within a segment (no '/').
private static func matchFrom(patternSegs: [String], pathSegs: [String], startAt: Int) -> Bool { ... }
}
FILE: Sources/llminty/FileScanner.swift

// Sources/llminty/FileScanner.swift
import Foundation
enum FileKind {
case swift, json, text, binary, unknown
}
struct RepoFile {
let relativePath: String
let absoluteURL: URL
let isDirectory: Bool
let kind: FileKind
let size: UInt64
}
enum ScanLimits {
static let maxFileBytes: UInt64 = 2 * 1024 * 1024 // 2 MB per file cap
}
struct FileScanner {
let root: URL
let matcher: IgnoreMatcher
func scan() throws -> [RepoFile] {
var results: [RepoFile] = []
let fm = FileManager.default
guard let enumerator = fm.enumerator(
at: root,
includingPropertiesForKeys: [.isDirectoryKey, .fileSizeKey],
options: [.skipsHiddenFiles],
errorHandler: { _, _ in true }
) else {
throw NSError(domain: "llminty", code: 1, userInfo: [NSLocalizedDescriptionKey: "Failed to enumerate directory"])
}
for case let url as URL in enumerator {
let rel = (url.path).path(replacingBase: root.path)
let rIsDir = (try? url.resourceValues(forKeys: [.isDirectoryKey]).isDirectory) ?? false
if matcher.isIgnored(rel, isDirectory: rIsDir) {
if rIsDir { enumerator.skipDescendants() }
continue
}
if rIsDir { continue }
let size = (try? url.resourceValues(forKeys: [.fileSizeKey]).fileSize).map { UInt64($0) } ?? 0
let ext = url.pathExtension.lowercased()
let kind: FileKind
switch ext {
case "swift": kind = .swift
case "json":  kind = .json
case "md", "yml", "yaml", "xml", "plist", "txt", "sh", "toml": kind = .text
case "dat", "bin": kind = .binary // ensure small .dat/.bin are binary too
default:
if size > ScanLimits.maxFileBytes { kind = .binary }
else if Self.seemsBinary(url: url) { kind = .binary }
else { kind = .unknown }
}
results.append(RepoFile(relativePath: rel, absoluteURL: url, isDirectory: false, kind: kind, size: size))
}
results.sort { $0.relativePath < $1.relativePath }
return results
}
static func seemsBinary(url: URL) -> Bool { ... }
}
private extension String {
func removingPrefix(_ p: String) -> String {
guard hasPrefix(p) else { return self }
return String(dropFirst(p.count))
}
func relativePath(from root: String) -> String { ... }
}
extension String {
func path(replacingBase base: String) -> String { ... }
}
FILE: Sources/llminty/SwiftAnalyzer.swift

import Foundation
import SwiftParser
import SwiftSyntax
// MARK: - Intermediate models
struct AnalyzedFile {
let file: RepoFile
let text: String
var declaredTypes: Set<String>
var publicAPIScoreRaw: Int
var referencedTypes: [String: Int] // name -> occurrences
var complexity: Int
var isEntrypoint: Bool
var outgoingFileDeps: [String]
var inboundRefCount: Int
}
// MARK: - Analyzer
final class SwiftAnalyzer {
func analyze(files: [RepoFile]) throws -> [AnalyzedFile] {
// Parse only Swift files
var analyzed: [AnalyzedFile] = []
analyzed.reserveCapacity(files.count)
for f in files where f.kind == .swift {
let text = (try? String(contentsOf: f.absoluteURL, encoding: .utf8)) ?? ""
let a = analyzeSwift(path: f.relativePath, text: text)
analyzed.append(a)
}
// Map declared types -> file
var typeToFile: [String: String] = [:]
for a in analyzed {
for t in a.declaredTypes { typeToFile[t, default: a.file.relativePath] = a.file.relativePath }
}
// Compute outgoing deps via referenced type → declared type mapping
for i in analyzed.indices {
var deps = Set<String>()
for (name, _) in analyzed[i].referencedTypes {
if let depPath = typeToFile[name], depPath != analyzed[i].file.relativePath {
deps.insert(depPath)
}
}
analyzed[i].outgoingFileDeps = Array(deps).sorted()
}
// Compute inbound counts
var inbound: [String: Int] = [:]
for a in analyzed {
for dep in a.outgoingFileDeps { inbound[dep, default: 0] += 1 }
}
for i in analyzed.indices {
analyzed[i].inboundRefCount = inbound[analyzed[i].file.relativePath] ?? 0
}
return analyzed
}
private func analyzeSwift(path: String, text: String) -> AnalyzedFile { ... }
}
// MARK: - Collector with SwiftSyntax
private struct CollectorContext {
var declaredTypes: Set<String> = []
var publicAPIScoreRaw: Int = 0
var referencedTypes: [String: Int] = [:]
var complexity: Int = 0
var isEntrypoint: Bool = false
var importedModules: Set<String> = []
var hasTopLevelCode: Bool = false
}
private final class SwiftCollector: SyntaxVisitor {
private var ctx: UnsafeMutablePointer<CollectorContext>
private var typeStack: [String] = []
init(context: inout CollectorContext)  {
self.ctx = withUnsafeMutablePointer(to: &context) { $0 }
super.init(viewMode: .sourceAccurate)
}
override func visit(_ node: ImportDeclSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visit(_ node: StructDeclSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visitPost(_ node: StructDeclSyntax)  { ... }
override func visit(_ node: ClassDeclSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visitPost(_ node: ClassDeclSyntax)  { ... }
override func visit(_ node: EnumDeclSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visitPost(_ node: EnumDeclSyntax)  { ... }
override func visit(_ node: ProtocolDeclSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visitPost(_ node: ProtocolDeclSyntax)  { ... }
override func visit(_ node: AttributeSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visit(_ node: SourceFileSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visitPost(_ node: SourceFileSyntax)  { ... }
// Types referenced
override func visit(_ node: IdentifierTypeSyntax) -> SyntaxVisitorContinueKind  { ... }
override func visit(_ node: MemberTypeSyntax) -> SyntaxVisitorContinueKind  { ... }
// Complexity: count control-flow keywords and boolean ops
override func visit(_ token: TokenSyntax) -> SyntaxVisitorContinueKind  { ... }
}
// MARK: - Small helpers
// Make this module-internal so Rendering.swift can reuse it
extension DeclModifierListSyntax {
var containsPublicOrOpen: Bool {
for m in self {
let k = m.name.text
if k == "public" || k == "open" { return true }
}
return false
}
}
extension Optional where Wrapped == DeclModifierListSyntax {
var containsPublicOrOpen: Bool { self?.containsPublicOrOpen ?? false }
}
private extension StructDeclSyntax {
func inheritanceClauseContains(type: String) -> Bool  {
if let clause = self.inheritanceClause {
for it in clause.inheritedTypes {
if it.type.trimmedDescription == type { return true }
}
}
return false
}
}
FILE: Sources/llminty/Scoring.swift

import Foundation
struct ScoredFile {
let analyzed: AnalyzedFile
let score: Double
let fanIn: Int
let pageRank: Double
}
final class Scoring {
struct Norm {
var fanInMax = 0
var pageRankMax = 0.0
var apiMax = 0
var influenceMax = 0
var complexityMax = 0
}
/// Compute a composite [0,1] score for each file.
/// Heuristics balance inbound references, PageRank, public API surface, "influence"
/// (outgoing refs) and measured complexity; + entrypoint bonus.
func score(analyzed: [AnalyzedFile]) -> [ScoredFile] {
// Precompute PR and fan-in
let pr = GraphCentrality.pageRank(analyzed)
var fanIn: [String: Int] = [:]
for a in analyzed {
fanIn[a.file.relativePath] = a.inboundRefCount
}
// Collect maxima for normalization
var norm = Norm()
for a in analyzed {
norm.fanInMax = max(norm.fanInMax, fanIn[a.file.relativePath] ?? 0)
norm.pageRankMax = max(norm.pageRankMax, pr[a.file.relativePath] ?? 0.0)
norm.apiMax = max(norm.apiMax, a.publicAPIScoreRaw)
// "Influence": number of distinct outgoing file deps (fan-out)
norm.influenceMax = max(norm.influenceMax, a.outgoingFileDeps.count)
norm.complexityMax = max(norm.complexityMax, a.complexity)
}
// Safe division
func nzDiv(_ num: Double, by den: Double) -> Double { den == 0 ? 0 : (num / den) }
var out: [ScoredFile] = []
out.reserveCapacity(analyzed.count)
for a in analyzed {
let fanInN   = nzDiv(Double(fanIn[a.file.relativePath] ?? 0), by: Double(norm.fanInMax))
let prN      = nzDiv(pr[a.file.relativePath] ?? 0.0, by: norm.pageRankMax)
let apiN     = nzDiv(Double(a.publicAPIScoreRaw), by: Double(norm.apiMax))
let inflN    = nzDiv(Double(a.outgoingFileDeps.count), by: Double(norm.influenceMax))
let cxN      = nzDiv(Double(a.complexity), by: Double(norm.complexityMax))
let entry    = a.isEntrypoint ? 1.0 : 0.0
// Weights: 5 equally weighted primary signals + entrypoint bonus
let score =
0.18 * fanInN +
0.18 * prN +
0.18 * apiN +
0.18 * inflN +
0.18 * cxN +
0.10 * entry
out.append(
ScoredFile(
analyzed: a,
score: max(0.0, min(1.0, score)),
fanIn: fanIn[a.file.relativePath] ?? 0,
pageRank: pr[a.file.relativePath] ?? 0.0
)
)
}
return out
}
}
FILE: Sources/llminty/JSONReducer.swift

import Foundation
/// Public, single entry point. Everything else is internal by default.
public struct JSONReducer {
/// Reduces a JSON string while preserving overall structure.
/// - Parameters:
///   - input: UTF-8 JSON (fragments allowed). If invalid, returned unchanged.
///   - arrayThreshold: Arrays longer than this are trimmed to first 3, comment, last 2.
///   - dictThreshold: Objects keep all collection entries and up to this many scalar entries.
/// - Returns: One-line JSON string with optional trim comments.
public static func reduceJSONPreservingStructure(_ input: String, arrayThreshold: Int, dictThreshold: Int) -> String {
guard
let data = input.data(using: .utf8),
let json = try? JSONSerialization.jsonObject(with: data, options: [.fragmentsAllowed])
else {
return input
}
let node = Reducer.reduce(any: json, arrayLimit: arrayThreshold, dictScalarLimit: dictThreshold)
return Stringifier.stringify(node)
}
// MARK: - Internal model
enum Node {
case number(Double)
case string(String)
case bool(Bool)
case null
case array([Node])
case object([(String, Node)], trimmed: Int) // trimmed = number of keys dropped
case arrayTrimmed(head: [Node], trimmedCount: Int, tail: [Node])
}
// MARK: - Reduction
enum Reducer {
static func reduce(any: Any, arrayLimit: Int, dictScalarLimit: Int) -> Node {
switch any {
case let n as NSNumber:
// NSNumber can represent both numbers and booleans; disambiguate via CFTypeID.
if CFGetTypeID(n) == CFBooleanGetTypeID() {
return .bool(n.boolValue)
} else {
return .number(n.doubleValue)
}
case let s as NSString:
return .string(s as String)
case _ as NSNull:
return .null
case let array as [Any]:
return reduceArray(array, arrayLimit: arrayLimit, dictScalarLimit: dictScalarLimit)
case let dict as [String: Any]:
return reduceObject(dict, arrayLimit: arrayLimit, dictScalarLimit: dictScalarLimit)
default:
// Fallback: stringify unknowns
return .string("\(any)")
}
}
private static func reduceArray(_ array: [Any], arrayLimit: Int, dictScalarLimit: Int) -> Node { ... }
private static func reduceObject(_ dict: [String: Any], arrayLimit: Int, dictScalarLimit: Int) -> Node { ... }
}
// MARK: - Stringify
enum Stringifier {
static func stringify(_ node: Node) -> String {
switch node {
case .number(let d):
if d.rounded(.towardZero) == d {
return String(Int(d))
}
return String(d)
case .string(let s):
return "\"" + escapeString(s) + "\""
case .bool(let b):
return b ? "true" : "false"
case .null:
return "null"
case .array(let items):
if items.isEmpty { return "[]" }
return "[ " + items.map(stringify).joined(separator: ", ") + " ]"
case .arrayTrimmed(let head, let trimmed, let tail):
var parts: [String] = []
parts.append(contentsOf: head.map(stringify))
parts.append("/* trimmed \(trimmed) items */")
parts.append(contentsOf: tail.map(stringify))
return "[ " + parts.joined(separator: ", ") + " ]"
case .object(let entries, let trimmed):
var pieces: [String] = []
pieces.reserveCapacity(entries.count + (trimmed > 0 ? 1 : 0))
for (k, v) in entries {
pieces.append("\"\(escapeString(k))\": \(stringify(v))")
}
if trimmed > 0 {
pieces.append("/* trimmed \(trimmed) keys */")
}
if pieces.isEmpty { return "{ ... }" }
return "{ " + pieces.joined(separator: ", ") + " }"
}
}
static func escapeString(_ s: String) -> String { ... }
}
}
FILE: Sources/llminty/Rendering.swift

import Foundation
import SwiftParser
import SwiftSyntax
// MARK: - Types used by the rest of the package
struct RenderedFile {
let relativePath: String
let content: String
}
final class Renderer {
enum RenderPolicy {
case signaturesOnly
case keepOneBodyPerTypeElideRest
case keepPublicBodiesElideOthers
case keepAllBodiesLightlyCondensed
}
// MARK: Entry points
func render(file: ScoredFile, score: Double) throws -> RenderedFile {
let policy = policyFor(score: score)
switch file.analyzed.file.kind {
case .swift:
let text = try renderSwift(text: file.analyzed.text, policy: policy)
return RenderedFile(relativePath: file.analyzed.file.relativePath, content: text)
case .json:
// Produce the exact “/* trimmed … */” markers the e2e test looks for.
let text = JSONReducer.reduceJSONPreservingStructure(
file.analyzed.text,
arrayThreshold: 5,
dictThreshold: 6
)
return RenderedFile(relativePath: file.analyzed.file.relativePath, content: text)
case .text, .unknown:
let text = Renderer.compactText(file.analyzed.text)
return RenderedFile(relativePath: file.analyzed.file.relativePath, content: text)
case .binary:
let text = "binary omitted; size=\(file.analyzed.file.size) bytes"
return RenderedFile(relativePath: file.analyzed.file.relativePath, content: text)
}
}
func renderSwift(text: String, policy: RenderPolicy) throws -> String { ... }
// Score -> policy mapping (inclusive boundaries)
func policyFor(score: Double) -> RenderPolicy { ... }
// MARK: - Text utilities
/// Compacts 3+ blank lines to 1.
static func compactText(_ s: String) -> String { ... }
/// Only used for non-keepAll policies.
private func canonicalizeEmptyBlocks(_ s: String) -> String { ... }
}
// MARK: - Rewriter
fileprivate final class ElideBodiesRewriter: SyntaxRewriter {
private let policy: Renderer.RenderPolicy
// Original source and location converter to slice exact text between braces.
private let sourceText: String
private let converter: SourceLocationConverter
// Track "keep-one" per container (type or extension).
private var containerStack: [String] = []
private var keptOne: Set<String> = []
init(policy: Renderer.RenderPolicy, sourceText: String, tree: SourceFileSyntax) {
self.policy = policy
self.sourceText = sourceText
self.converter = SourceLocationConverter(file: "", tree: tree)
super.init(viewMode: .sourceAccurate)
}
// Container bookkeeping
override func visit(_ node: StructDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: ClassDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: EnumDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: ExtensionDeclSyntax) -> DeclSyntax { ... }
// MARK: - Function-like
override func visit(_ node: FunctionDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: InitializerDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: DeinitializerDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: SubscriptDeclSyntax) -> DeclSyntax { ... }
override func visit(_ node: VariableDeclSyntax) -> DeclSyntax { ... }
// MARK: - Helpers
private func withContainer<T>(name: String, _ body: () -> T) -> T { ... }
private func markFirstIfNeeded() -> Bool { ... }
private func isPublicOrOpen(_ modifiers: DeclModifierListSyntax?) -> Bool { ... }
// Preserve leading/trailing trivia of the original declaration around a replacement.
private func withTrivia<T: DeclSyntaxProtocol>(from original: T, replaceWith replacement: DeclSyntax) -> DeclSyntax { ... }
// Build sentinel comment using line count + short hash of the original *source* body text.
private func sentinel(lines: Int, for text: String) -> String { ... }
// Replace function/init/deinit by re-parsing the signature and attaching a simple body.
private func parseDeclReplacingBody(of fn: FunctionDeclSyntax, withSentinelFor body: CodeBlockSyntax) -> DeclSyntax { ... }
private func parseDeclReplacingBody(of ini: InitializerDeclSyntax, withSentinelFor body: CodeBlockSyntax) -> DeclSyntax { ... }
private func parseDeclReplacingBody(of deinitDecl: DeinitializerDeclSyntax, withSentinelForLines lines: Int) -> DeclSyntax { ... }
private func parseDeclReplacingAccessor(of sub: SubscriptDeclSyntax, accessor: AccessorBlockSyntax) -> DeclSyntax { ... }
private func parseDeclReplacingAccessor(of varDecl: VariableDeclSyntax, accessor: AccessorBlockSyntax) -> DeclSyntax { ... }
// MARK: - Measuring exact body/accessor source
private func bodyStats(from block: CodeBlockSyntax) -> (lines: Int, text: String) { ... }
private func accessorStats(from accessor: AccessorBlockSyntax) -> (lines: Int, text: String) { ... }
private func exactTextInsideBraces(of block: CodeBlockSyntax) -> String { ... }
private func exactTextInsideBraces(of accessor: AccessorBlockSyntax) -> String { ... }
private func substringUTF8(_ s: String, start: Int, end: Int) -> String { ... }
private func normalizeNewlines(_ s: String) -> String { ... }
// MARK: - Hashing
private static func fnv1a64(_ s: String) -> UInt64 { ... }
}
FILE: Sources/llminty/GraphCentrality.swift

import Foundation
enum GraphCentrality {
// PageRank on file dependency graph (A -> B means A depends on B)
static func pageRank(_ analyzed: [AnalyzedFile],
damping: Double = 0.85,
iterations: Int = 20) -> [String: Double] {
let files: [String] = analyzed.map { $0.file.relativePath }
let index: [String: Int] = Dictionary(uniqueKeysWithValues: files.enumerated().map { ($1, $0) })
let n = files.count
guard n > 0 else { return [:] }
// Outgoing edges (by index)
var outEdges: [Set<Int>] = Array(repeating: [], count: n)
for a in analyzed {
let i = index[a.file.relativePath]!
for dep in a.outgoingFileDeps {
if let j = index[dep] { outEdges[i].insert(j) }
}
}
// Init PR
var pr = Array(repeating: 1.0 / Double(n), count: n)
var newPR = Array(repeating: 0.0, count: n)
let base = (1.0 - damping) / Double(n)
for _ in 0..<iterations {
// Distribute rank
for i in 0..<n { newPR[i] = base }
for i in 0..<n {
let outs = outEdges[i]
if outs.isEmpty {
// Dangling node: spread evenly
let share = damping * pr[i] / Double(n)
for j in 0..<n { newPR[j] += share }
} else {
let share = damping * pr[i] / Double(outs.count)
for j in outs { newPR[j] += share }
}
}
pr = newPR
}
// Map back to paths
var out: [String: Double] = [:]
for (p, i) in index { out[p] = pr[i] }
return out
}
/// Dependency-aware emission order:
/// If A depends on B, emit B before A. When multiple nodes are available,
/// prefer higher score, then lexicographic path.
static func orderDependencyAware(_ scored: [ScoredFile]) -> [ScoredFile]  { ... }
}
FILE: Sources/llminty/App.swift

import Foundation
enum BuiltInExcludes {
static func defaultPatterns(outputFileName: String) -> [String] { ... }
}
/// Aggressively trims blank lines for final output while keeping exactly one
/// blank line after each "FILE: " header. Also:
/// - trims trailing spaces,
/// - collapses 3+ newlines to 2 during pre-pass,
/// - removes all other blank-only lines.
/// Returns a string that always ends with a single trailing newline.
func postProcessMinty(_ s: String) -> String { ... }
public struct LLMintyApp {
public init() { ... }
}
public extension LLMintyApp {
func run() throws { ... }
}
FILE: Tests/LLMintyTests/GraphCentralityTests.swift

import XCTest
@testable import llminty
final class GraphCentralityTests: XCTestCase {
private func analyzed(_ path: String, deps: [String]) -> AnalyzedFile { ... }
func testDependencyAwareOrder() { ... }
}
FILE: Sources/llminty/main.swift

import Foundation
// Top-level entrypoint for the executable target.
// (Do NOT use @main if the module has any other top-level code.)
do {
try LLMintyApp().run()
} catch {
fputs("llminty: \(error.localizedDescription)\n", stderr)
exit(1)
}
FILE: Tests/LLMintyTests/SwiftAnalyzerTests.swift

import XCTest
@testable import llminty
final class SwiftAnalyzerTests: XCTestCase {
func testEntrypointPublicAPIAndRefs() throws { ... }
}
FILE: Tests/LLMintyTests/GoldenSnapshotTests.swift

// Tests/LLMintyTests/GoldenSnapshotTests.swift
import XCTest
@testable import llminty
final class GoldenSnapshotTests: XCTestCase {
// MARK: - Paths & discovery
/// Repo root from this source file (works in SPM + Xcode).
private func repoRoot(_ file: StaticString = #filePath) -> URL { ... }
/// Fixtures directory resolution with env override, #file anchor, and repo-root fallback.
private func fixturesDir() -> URL { ... }
private func fixturesPath(_ name: String) -> URL { ... }
// MARK: - Models
private struct RegenSpec: Codable { var should_generate: Bool }
// MARK: - Tests
func testGoldenAgainstSnapshotFixtures() throws { ... }
func testRegenerateExpectedAndContractIfRequested() throws { ... }
// MARK: - Pipeline used by both tests
func runMintyOnZippedSnapshot(_ zip: URL) throws -> String { ... }
}
FILE: Tests/LLMintyTests/SnapshotE2ETests.swift

// Tests/LLMintyTests/SnapshotE2ETests.swift
import XCTest
@testable import llminty
final class SnapshotE2ETests: XCTestCase {
// MARK: - Helpers
/// Capture the content of a FILE: <path> block directly from the full output text.
/// Tolerates \n or \r\n and zero or more blank lines after the header.
private func captureFileSection(fullText: String, path: String) -> String? { ... }
/// Find the byte offset of a "FILE: <path>" header inside the full minty text.
private func fileHeaderOffset(in fullText: String, path: String) -> Int? { ... }
/// List all FILE headers in the full text (for targeted debugging on failure).
private func listAllHeaders(in fullText: String) -> [String] { ... }
/// Assert a regex exists in text; on failure, print a short preview.
private func assertRegex(
_ text: String,
_ pattern: String,
_ message: String,
file: StaticString = #filePath,
line: UInt = #line
) { ... }
// MARK: - Test
func testMiniRepoEndToEndContract() throws { ... }
}
FILE: Tests/LLMintyTests/TestSupport.swift

// Tests/LLMintyTests/TestSupport.swift
import Foundation
import XCTest
@testable import llminty
enum TestSupport {
// Locate repo root by walking up to Package.swift
static func projectRoot(file: String = #filePath) -> URL { ... }
static func fixturesDir() -> URL { ... }
static func fixtureURLIfExists(_ name: String) -> URL? { ... }
// Unzip with /usr/bin/unzip (available on macOS CI)
@discardableResult
static func unzip(_ zip: URL, to dest: URL) throws -> URL { ... }
// Run the app in given directory and return minty.txt contents
static func runLLMinty(in dir: URL) throws -> String { ... }
// Ensure framing is normalized the same way production does
static func normalized(_ s: String) -> String { ... }
// Simple line diff with small context; returns nil if equal
static func diffLines(expected: String, actual: String, context: Int = 2) -> String? { ... }
// Parse minty into { "path" : "content" }
static func parseMintySections(_ s: String) -> [String: String] { ... }
// MARK: - Contracts
struct ContractSpec: Codable, Equatable {
var version: Int
var must_include_files: [String]
var must_have_tokens: [String: [String]]
}
struct RegenerateConfig: Codable, Equatable {
var should_generate: Bool
}
static func defaultContract() -> ContractSpec { ... }
static func loadContractSpecIfAny() -> ContractSpec? { ... }
static func saveContractSpec(_ spec: ContractSpec) throws { ... }
static func loadRegenerateConfig() -> RegenerateConfig? { ... }
static func saveRegenerateConfig(_ cfg: RegenerateConfig) throws { ... }
}
private extension JSONEncoder {
static var withPretty: JSONEncoder {
let enc = JSONEncoder()
enc.outputFormatting = [.prettyPrinted, .sortedKeys, .withoutEscapingSlashes]
return enc
}
}
FILE: Tests/LLMintyTests/ChecklistContractTests.swift

// Tests/LLMintyTests/ChecklistContractTests.swift
import XCTest
@testable import llminty
final class ChecklistContractTests: XCTestCase {
private var fixturesDir: URL {
URL(fileURLWithPath: #file)
.deletingLastPathComponent()
.appendingPathComponent("Fixtures", isDirectory: true)
}
private var contractSpecURL: URL { fixturesDir.appendingPathComponent("contract_spec.json") }
private var zipURL: URL { fixturesDir.appendingPathComponent("LLMinty-nohidden.zip") }
struct Contract: Codable {
struct Entry: Codable { var file: String; var symbols: [String] }
var need: [Entry]
var can_elide: [Entry]
}
func testChecklistAgainstSnapshotFixtures() throws { ... }
private func findSection(in minty: String, forPath path: String) -> String? { ... }
}
FILE: Tests/LLMintyTests/LLMintyTests.swift

import XCTest
@testable import llminty
final class LLMintyTests: XCTestCase {
// End-to-end: builds a mini project, runs the app, checks minty.txt framing and ignore behavior.
func testEndToEndRunCreatesMintyFile() throws { ... }
// Compaction policy: keep exactly one blank line after each FILE header, drop others,
// but allow a single terminal blank line (trailing newline in the file).
func testKeepsOneBlankAfterHeadersAndDropsOthers() { ... }
}
FILE: Tests/LLMintyTests/RegenerationGate.swift

// Tests/LLMintyTests/TestSupport/RegenerationGate.swift
import Foundation
import XCTest
/// Toggle file at repo root (by default) with shape: {"should_generate": true|false}
/// You can override the location by setting the env var LLMINTY_REGENERATE_FLAG_PATH.
enum RegenerationGate {
struct Flag: Codable, Equatable {
var should_generate: Bool
}
/// Resolve the JSON flag URL deterministically relative to the repo root, unless overridden.
static func flagURL(filePath: StaticString = #filePath) -> URL { ... }
static func read(_ url: URL) -> Flag? { ... }
@discardableResult
static func write(_ flag: Flag, to url: URL) throws -> URL { ... }
/// Runs `work()` if flag exists and is true, and **always** flips it back to false afterward.
/// Returns `true` iff the regeneration branch was executed.
@discardableResult
static func withGate(filePath: StaticString = #filePath, _ work: () throws -> Void) throws -> Bool { ... }
}
FILE: Tests/LLMintyTests/RenderingTests.swift

import Foundation
import XCTest
@testable import llminty
final class RenderingTests: XCTestCase {
// Minimal, local regex helpers (pure XCTest; no external test utilities).
private static let sentinelPattern = #"/\*\s*elided-implemented;\s*lines=\d+;\s*h=[0-9a-f]{8,12}\s*\*/"#
private static let emptyPattern     = #"/\*\s*empty\s*\*/"#
private func assertMatches(_ text: String, pattern: String, file: StaticString = #filePath, line: UInt = #line) { ... }
private func assertNotMatches(_ text: String, pattern: String, file: StaticString = #filePath, line: UInt = #line) { ... }
// MARK: - Baseline
/// Maps score to policy.
func testPolicyForThresholds() { ... }
/// Policy cutoffs are inclusive.
func testPolicyBoundariesAreInclusiveAtCutoffs() { ... }
// MARK: - Core body elision / sentinels
/// Emits rich sentinel when bodies are elided (signaturesOnly baseline).
func testElidedFuncUsesRichSentinel() throws { ... }
/// Sentinel hash is stable for identical input.
func testSentinelHashIsStableForSameInput() throws { ... }
/// Rendering routes to policy by score and uses rich sentinels for elided non-public bodies.
func testRenderRoutingUsesScoreToSelectPolicy() throws { ... }
/// Keep-all preserves bodies and `{ ... }`.
func testKeepAllBodiesDoesNotElideOrCanonicalize() throws { ... }
/// Under keep-public, `open` kept; `internal`/`package` elided with rich sentinel; truly empty becomes `{ /* empty */ }`.
func testOpenIsKept_InternalAndPackageAreElided() throws { ... }
/// Keep-one keeps only the first executable per container; elided ones use rich sentinel.
func testOneBodyPerContainerOnlyFirstExecutableIsKept() throws { ... }
/// Computed properties: accessors that are elided use rich sentinel when non-empty; do not claim the keep-one slot.
func testComputedPropertiesDoNotCountTowardOne() throws { ... }
/// Extensions are separate containers for keep-one.
func testExtensionsAreSeparateContainers() throws { ... }
/// Accessors use rich sentinel whenever elided and non-empty (not only under `.signaturesOnly`).
func testAccessorsUseSentinelWhenElided() throws { ... }
/// NEW: Implicit getter bodies must produce rich sentinel when elided (regression test).
func testImplicitGetterComputedPropertyUsesSentinelWhenElided() throws { ... }
/// Empty `{ ... }` canonicalized to `{ /* empty */ }` unless keep-all; also assert rich sentinel appears for non-empty elisions.
func testCanonicalizeEmptyBlocksOnlyWhenPolicyIsNotKeepAll() throws { ... }
/// Compacts 3+ blank lines to 1 for text and unknown files.
func testTextAndUnknownWhitespaceIsCompacted() throws { ... }
/// Binary files show a size placeholder.
func testBinaryFilesEmitSizePlaceholder() throws { ... }
// MARK: - New rendering coverage
func testSubscriptAccessorsUseSentinelWhenElided() throws { ... }
func testDeinitUsesSentinelWhenElided() throws { ... }
// MARK: - Trivia & sentinel rawness regression guards
/// Do not glue closing braces to subsequent `// MARK:` lines or next decls.
// Replace this whole test in RenderingTests.swift
func testPreservesTriviaAroundMarksAndBetweenDecls() throws { ... }
/// The sentinel must be computed from the *exact* body text, including blank lines.
func testSentinelUsesExactBodyTextForLinesAndHash() throws { ... }
}
FILE: Tests/LLMintyTests/ScoringTests.swift

import XCTest
@testable import llminty
final class ScoringTests: XCTestCase {
func testScoringWeightsAndEntrypointBonus() { ... }
}
FILE: Package.swift

// swift-tools-version: 6.0
import PackageDescription
let package = Package(
name: "LLMinty",
platforms: [
.macOS(.v13)
],
products: [
.executable(name: "llminty", targets: ["llminty"])
],
dependencies: [
// Match your Swift 6.1 toolchain. 601.x == SwiftSyntax for Swift 6.1
.package(url: "https://github.com/swiftlang/swift-syntax.git", exact: "601.0.1")
],
targets: [
.executableTarget(
name: "llminty",
dependencies: [
.product(name: "SwiftParser", package: "swift-syntax"),
.product(name: "SwiftSyntax", package: "swift-syntax")
],
path: "Sources/llminty"
),
.testTarget(
name: "LLMintyTests",
dependencies: ["llminty"],
path: "Tests/LLMintyTests",
resources: [
.copy("Fixtures")
]
)
]
)
FILE: README.md

# LLMinty
Single-command CLI that emits a **token-efficient bundle** of a Swift repository for LLMs.
* **Command:** `llminty` (no args)
* **Output:** `./minty.txt` at the repo root
* **Ignore file:** `.mintyignore` (gitignore-style: globs, `!` negation, root-anchored `/`, dir `/` suffix, `#` comments)
* **Deterministic:** Given the same repo + ignore rules, the output is deterministic.
* **Swift toolchain:** Swift **6.1** compatible (package pins `swift-syntax` **601.0.1**).
---
## Quick install (Homebrew)
We publish prebuilt macOS tarballs as GitHub release assets and provide a small Homebrew tap for easy installation.
One-time tap + install:
```bash
brew tap 3lvis/llminty
brew install llminty
```
One-liner (auto-taps if needed):
```bash
brew install 3lvis/llminty/llminty
```
Build-from-source (if you prefer):
```bash
git clone git@github.com:3lvis/LLMinty.git
cd LLMinty
swift build -c release
# copy to a bin dir (adjust for Intel/Apple Silicon system)
cp .build/*/release/llminty /usr/local/bin/   # or /opt/homebrew/bin/
```
Verify install:
```bash
which llminty
llminty --help
file "$(which llminty)"   # check architecture (arm64 vs x86_64)
```
> Note: Homebrew installs use the tarball you upload to GitHub Releases. To publish a new release, create a Git tag (e.g. `v0.1.1`) and push it — the release workflow will build and attach tarballs.
---
## Usage
Run from the **root of the Swift repo you want to condense**:
```bash
llminty
# → prints: "Created ./minty.txt (N files)"
```
This writes `minty.txt` with concatenated, minimally rendered source for the most important files first.
Output framing example:
```
FILE: Sources/MyModule/Foo.swift

struct Foo { ... }
```
Each file has a single blank line after the `FILE:` header and the final file ends with a trailing newline.
---
## What gets included (short)
LLMinty walks the repo, categorizes files, **ranks** them, and **renders** them to minimize tokens while preserving structure.
* **Ranking signals:** graph centrality (fan-in / PageRank), public API surface, type influence, complexity proxy, entrypoint indicators.
* **Rendering:** signatures preserved; low-value bodies elided to `{ ... }`; JSON reduced by head/tail sampling with `// trimmed …` annotations; text/unknown files included with caps; binaries skipped.
* **Size cap:** per-file cap (2 MB default).
* **Built-in excludes:** VCS/editor noise, `.build/`, derived Xcode artifacts, dependency folders, large assets, and `minty.txt` itself (self-exclude).
### `.mintyignore`
Use `.mintyignore` at repo root (gitignore syntax) to fine-tune inclusion. Example:
```gitignore
# Ignore tests and samples
Tests/
Examples/
**/*.png
# Keep golden snapshot sources
!Tests/**/Fixtures/**/*.swift
```
> Use `.mintyignore` (not `.llmintyignore`).
---
## Developing
```bash
swift build
swift test
```
Key sources:
* `App.swift`, `main.swift` – CLI wiring
* `FileScanner.swift`, `IgnoreMatcher.swift` – repo walk & ignore engine
* `SwiftAnalyzer.swift`, `Rendering.swift`, `Scoring.swift`, `GraphCentrality.swift`, `JSONReducer.swift` – analysis & rendering
---
## CI: auto-refresh `minty.txt`
You already added `.github/workflows/llminty.yml`. This workflow builds LLMinty on `macos-14`, runs it at the repo root, and auto-commits `minty.txt` when it changes.
Workflow summary:
* Trigger: `push` to `main` and `pull_request`
* Steps: checkout → `swift build -c release` → run `./.build/release/llminty` → commit `minty.txt` (if changed)
Alternative CI behavior:
* Upload `minty.txt` as a PR artifact instead of committing (use `actions/upload-artifact`).
* Limit commits to `push` on `main` using `if: github.event_name == 'push' && github.ref == 'refs/heads/main'`.
---
## Release automation (build + upload binaries)
Use the `release.yml` workflow to create GitHub Release assets on tag push (e.g. `v0.1.0`). The release job builds LLMinty on the macOS runner and uploads a tarball named like:
```
llminty-v0.1.0-macos-arm64.tar.gz
```
If you want both `arm64` and `x86_64` artifacts automatically you can:
* add a self-hosted Intel macOS runner and run a separate job for x86\_64, or
* build one arch locally and upload the other to the same release (via `gh` or the API).
---
## Homebrew tap notes / troubleshooting
* Tap repo: `github.com/3lvis/homebrew-llminty` (formula `Formula/llminty.rb`). The formula expects a release tarball asset with the binary inside.
* If `brew audit` or `brew install` shows stale results, the local tapped clone may be out of sync. Refresh with:
```bash
# re-clone the tap used by Homebrew
brew untap 3lvis/llminty
brew tap 3lvis/llminty
```
* If Homebrew attempts to build from source and SPM uses manifest-time plugins, macOS sandboxing can cause `sandbox_apply: Operation not permitted`. To avoid that, the tap uses prebuilt tarballs so Homebrew installs the binary directly.
---
## FAQ
**Does LLMinty modify my repo?**
Only writes `minty.txt` at the root. Nothing else is changed.
**Should I commit `minty.txt`?**
Many teams do — useful for diffing and CI checks. Up to you.
**Will it run on CI?**
Yes — see the `.github/workflows/llminty.yml` you added.
---
## License
`MIT`
FILE: Tests/LLMintyTests/FileScannerTests.swift

// Tests/LLMintyTests/FileScannerTests.swift
import XCTest
@testable import llminty
final class FileScannerTests: XCTestCase {
func testScanningKindsAndIgnores() throws { ... }
}
FILE: Tests/LLMintyTests/Fixtures/contract_spec.json

{ "version": 2, "must_include_files": ["Sources/llminty/IgnoreMatcher.swift", "Sources/llminty/FileScanner.swift", "Sources/llminty/SwiftAnalyzer.swift", /* trimmed 5 items */, "Sources/llminty/main.swift", "Package.swift"], "must_have_tokens": { "Sources/llminty/Scoring.swift": ["func score("], "Sources/llminty/GraphCentrality.swift": ["orderDependencyAware("], "Sources/llminty/Rendering.swift": ["SwiftPolicy", "func policyFor(", "func renderSwift(", "lightlyCondenseWhitespace(", "compactText("], "Sources/llminty/SwiftAnalyzer.swift": ["final class SwiftAnalyzer", "func analyze(", "analyzeSwift(", /* trimmed 9 items */, "TokenSyntax", "inheritanceClauseContains("], "Sources/llminty/JSONReducer.swift": ["reduceJSONPreservingStructure(", "reduce(", "reduceArray(", /* trimmed 1 items */, "stringify(", "escape("], "Sources/llminty/FileScanner.swift": ["func scan()", "seemsBinary(", "relativePath(from", "path(replacingBase"], /* trimmed 2 keys */ } }
FILE: Tests/LLMintyTests/Fixtures/expected_minty.txt

FILE: Sources/llminty/IgnoreMatcher.swift

import Foundation
/// Minimal gitignore-like engine with globs (* ? **), dir-trailing '/', root-anchored '/' and negation '!'
/// Evaluation order: built-ins first (exclude bias), then user's .mintyignore (last match wins)
struct IgnoreMatcher {
struct Pattern {
let negated: Bool
let dirOnly: Bool
let anchorRoot: Bool
let raw: String
let segments: [String] // split on '/'
}
private let ordered: [Pattern]
init(builtInPatterns: [String], userFileText: String) throws {
var list: [Pattern] = []
for p in builtInPatterns { if let pat = Self.parse(line: p) { list.append(pat) } }
for line in userFileText.components(separatedBy: .newlines) {
if let pat = Self.parse(line: line) { list.append(pat) }
}
self.ordered = list
}
// MARK: - Parser
private static func parse(line: String) -> Pattern? { /* elided-implemented; lines=19; h=7ce40768c0 */ }
// MARK: - Eval
func isIgnored(_ relativePath: String, isDirectory: Bool) -> Bool { /* elided-implemented; lines=26; h=7c1dde36c6 */ }
private static func match(pattern p: Pattern, pathSegments: [String]) -> Bool { /* elided-implemented; lines=2; h=d102b61226 */ }
// Segment matcher for '*' and '?'
private static func matchSegment(_ pat: String, _ txt: String) -> Bool { /* elided-implemented; lines=30; h=ec0f3b0a8f */ }
// '**' matches zero or more segments. '*' matches within a segment (no '/').
private static func matchFrom(patternSegs: [String], pathSegs: [String], startAt: Int) -> Bool { /* elided-implemented; lines=20; h=7e46aaf6ed */ }
}
FILE: Sources/llminty/FileScanner.swift

import Foundation
enum FileKind {
case swift, json, text, binary, unknown
}
struct RepoFile {
let relativePath: String
let absoluteURL: URL
let isDirectory: Bool
let kind: FileKind
let size: UInt64
}
enum ScanLimits {
static let maxFileBytes: UInt64 = 2 * 1024 * 1024 // 2 MB per file cap
}
struct FileScanner {
let root: URL
let matcher: IgnoreMatcher
func scan() throws -> [RepoFile] {
var results: [RepoFile] = []
let fm = FileManager.default
guard let enumerator = fm.enumerator(
at: root,
includingPropertiesForKeys: [.isDirectoryKey, .fileSizeKey],
options: [.skipsHiddenFiles],
errorHandler: { _, _ in true } // keep going
) else {
throw NSError(domain: "llminty", code: 1, userInfo: [NSLocalizedDescriptionKey: "Failed to enumerate directory"])
}
for case let url as URL in enumerator {
let rel = (url.path).path(replacingBase: root.path)
// Never include leading slash
let relClean = rel.hasPrefix("/") ? String(rel.dropFirst()) : rel
let rIsDir = (try? url.resourceValues(forKeys: [.isDirectoryKey]).isDirectory) ?? false
if matcher.isIgnored(relClean, isDirectory: rIsDir) {
if rIsDir { enumerator.skipDescendants() }
continue
}
if rIsDir { continue }
let size = (try? url.resourceValues(forKeys: [.fileSizeKey]).fileSize).map { UInt64($0) } ?? 0
let ext = url.pathExtension.lowercased()
let kind: FileKind
switch ext {
case "swift": kind = .swift
case "json":  kind = .json
case "md", "yml", "yaml", "xml", "plist", "txt", "sh", "toml": kind = .text
default:
if size > ScanLimits.maxFileBytes { kind = .binary }
else if Self.seemsBinary(url: url) { kind = .binary }
else { kind = .unknown }
}
results.append(RepoFile(relativePath: relClean, absoluteURL: url, isDirectory: false, kind: kind, size: size))
}
// Deterministic stable path sort
results.sort { $0.relativePath < $1.relativePath }
return results
}
static func seemsBinary(url: URL) -> Bool { /* elided-implemented; lines=11; h=e34c775dce */ }
}
// MARK: - Path helpers
private extension String {
func removingPrefix(_ p: String) -> String {
guard hasPrefix(p) else { return self }
return String(dropFirst(p.count))
}
func relativePath(from root: String) -> String { /* elided-implemented; lines=5; h=b7db04440f */ }
}
extension String {
func path(replacingBase base: String) -> String { /* elided-implemented; lines=3; h=ba7b3d4170 */ }
}
FILE: Sources/llminty/SwiftAnalyzer.swift

import Foundation
import SwiftParser
import SwiftSyntax
// MARK: - Intermediate models
struct AnalyzedFile {
let file: RepoFile
let text: String
var declaredTypes: Set<String>
var publicAPIScoreRaw: Int
var referencedTypes: [String: Int] // name -> occurrences
var complexity: Int
var isEntrypoint: Bool
var outgoingFileDeps: [String]
var inboundRefCount: Int
}
// MARK: - Analyzer
final class SwiftAnalyzer {
func analyze(files: [RepoFile]) throws -> [AnalyzedFile] {
// Parse only Swift files
var analyzed: [AnalyzedFile] = []
analyzed.reserveCapacity(files.count)
for f in files where f.kind == .swift {
let text = (try? String(contentsOf: f.absoluteURL, encoding: .utf8)) ?? ""
let a = analyzeSwift(path: f.relativePath, text: text)
analyzed.append(a)
}
// Map declared types -> file
var typeToFile: [String: String] = [:]
for a in analyzed {
for t in a.declaredTypes { typeToFile[t, default: a.file.relativePath] = a.file.relativePath }
}
// Compute outgoing deps via referenced type → declared type mapping
for i in analyzed.indices {
var deps = Set<String>()
for (name, _) in analyzed[i].referencedTypes {
if let depPath = typeToFile[name], depPath != analyzed[i].file.relativePath {
deps.insert(depPath)
}
}
analyzed[i].outgoingFileDeps = Array(deps).sorted()
}
// Compute inbound counts
var inbound: [String: Int] = [:]
for a in analyzed {
for dep in a.outgoingFileDeps { inbound[dep, default: 0] += 1 }
}
for i in analyzed.indices {
analyzed[i].inboundRefCount = inbound[analyzed[i].file.relativePath] ?? 0
}
return analyzed
}
private func analyzeSwift(path: String, text: String) -> AnalyzedFile { /* elided-implemented; lines=17; h=77df369873 */ }
}
// MARK: - Collector with SwiftSyntax
private struct CollectorContext {
var declaredTypes: Set<String> = []
var publicAPIScoreRaw: Int = 0
var referencedTypes: [String: Int] = [:]
var complexity: Int = 0
var isEntrypoint: Bool = false
var importedModules: Set<String> = []
var hasTopLevelCode: Bool = false
}
private final class SwiftCollector: SyntaxVisitor {
private var ctx: UnsafeMutablePointer<CollectorContext>
private var typeStack: [String] = []
init(context: inout CollectorContext)  {
self.ctx = withUnsafeMutablePointer(to: &context) { $0 }
super.init(viewMode: .sourceAccurate)
}
override func visit(_ node: ImportDeclSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=3; h=d518c2787c */ }
override func visit(_ node: StructDeclSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=7; h=0cbdbd2709 */ }
override func visitPost(_ node: StructDeclSyntax) { /* elided-implemented; lines=1; h=9258e083d9 */ }
override func visit(_ node: ClassDeclSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=6; h=88327f0a72 */ }
override func visitPost(_ node: ClassDeclSyntax) { /* elided-implemented; lines=1; h=9258e083d9 */ }
override func visit(_ node: EnumDeclSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=6; h=88327f0a72 */ }
override func visitPost(_ node: EnumDeclSyntax) { /* elided-implemented; lines=1; h=9258e083d9 */ }
override func visit(_ node: ProtocolDeclSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=6; h=214e739581 */ }
override func visitPost(_ node: ProtocolDeclSyntax) { /* elided-implemented; lines=1; h=9258e083d9 */ }
override func visit(_ node: AttributeSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=3; h=4c06e70218 */ }
override func visit(_ node: SourceFileSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=8; h=080907ee1f */ }
override func visitPost(_ node: SourceFileSyntax)  { /* empty */ }
// Types referenced
override func visit(_ node: IdentifierTypeSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=4; h=256a8c808f */ }
override func visit(_ node: MemberTypeSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=4; h=90e5e5cb5d */ }
// Complexity: count control-flow keywords and boolean ops
override func visit(_ token: TokenSyntax) -> SyntaxVisitorContinueKind { /* elided-implemented; lines=11; h=b382655b0e */ }
}
// MARK: - Small helpers
// Make this module-internal so Rendering.swift can reuse it
extension DeclModifierListSyntax {
var containsPublicOrOpen : Bool { /* elided-implemented; lines=6; h=1274ea2fb3 */ }
}
extension Optional where Wrapped == DeclModifierListSyntax {
var containsPublicOrOpen : Bool { /* elided-implemented; lines=1; h=5e698e2910 */ }
}
private extension StructDeclSyntax {
func inheritanceClauseContains(type: String) -> Bool  {
if let clause = self.inheritanceClause {
for it in clause.inheritedTypes {
if it.type.trimmedDescription == type { return true }
}
}
return false
}
}
FILE: Sources/llminty/Scoring.swift

import Foundation
struct ScoredFile {
let analyzed: AnalyzedFile
let score: Double
let fanIn: Int
let pageRank: Double
}
final class Scoring {
struct Norm {
var fanInMax = 0
var pageRankMax = 0.0
var apiMax = 0
var influenceMax = 0
var complexityMax = 0
}
/// Compute a composite [0,1] score for each file.
/// Heuristics balance inbound references, PageRank, public API surface, "influence"
/// (outgoing refs) and measured complexity; + entrypoint bonus.
func score(analyzed: [AnalyzedFile]) -> [ScoredFile] {
// Precompute PR and fan-in
let pr = GraphCentrality.pageRank(analyzed)
var fanIn: [String: Int] = [:]
for a in analyzed {
fanIn[a.file.relativePath] = a.inboundRefCount
}
// Collect maxima for normalization
var norm = Norm()
for a in analyzed {
norm.fanInMax = max(norm.fanInMax, fanIn[a.file.relativePath] ?? 0)
norm.pageRankMax = max(norm.pageRankMax, pr[a.file.relativePath] ?? 0.0)
norm.apiMax = max(norm.apiMax, a.publicAPIScoreRaw)
// "Influence": number of distinct outgoing file deps (fan-out)
norm.influenceMax = max(norm.influenceMax, a.outgoingFileDeps.count)
norm.complexityMax = max(norm.complexityMax, a.complexity)
}
// Safe division
func nzDiv(_ num: Double, by den: Double) -> Double { den == 0 ? 0 : (num / den) }
var out: [ScoredFile] = []
out.reserveCapacity(analyzed.count)
for a in analyzed {
let fanInN   = nzDiv(Double(fanIn[a.file.relativePath] ?? 0), by: Double(norm.fanInMax))
let prN      = nzDiv(pr[a.file.relativePath] ?? 0.0, by: norm.pageRankMax)
let apiN     = nzDiv(Double(a.publicAPIScoreRaw), by: Double(norm.apiMax))
let inflN    = nzDiv(Double(a.outgoingFileDeps.count), by: Double(norm.influenceMax))
let cxN      = nzDiv(Double(a.complexity), by: Double(norm.complexityMax))
let entry    = a.isEntrypoint ? 1.0 : 0.0
// Weights: 5 equally weighted primary signals + entrypoint bonus
let score =
0.18 * fanInN +
0.18 * prN +
0.18 * apiN +
0.18 * inflN +
0.18 * cxN +
0.10 * entry
out.append(
ScoredFile(
analyzed: a,
score: max(0.0, min(1.0, score)),
fanIn: fanIn[a.file.relativePath] ?? 0,
pageRank: pr[a.file.relativePath] ?? 0.0
)
)
}
return out
}
}
FILE: Sources/llminty/GraphCentrality.swift

import Foundation
enum GraphCentrality {
// PageRank on file dependency graph (A -> B means A depends on B)
static func pageRank(_ analyzed: [AnalyzedFile],
damping: Double = 0.85,
iterations: Int = 20) -> [String: Double] {
let files: [String] = analyzed.map { $0.file.relativePath }
let index: [String: Int] = Dictionary(uniqueKeysWithValues: files.enumerated().map { ($1, $0) })
let n = files.count
guard n > 0 else { return [:] }
// Outgoing edges (by index)
var outEdges: [Set<Int>] = Array(repeating: [], count: n)
for a in analyzed {
let i = index[a.file.relativePath]!
for dep in a.outgoingFileDeps {
if let j = index[dep] { outEdges[i].insert(j) }
}
}
// Init PR
var pr = Array(repeating: 1.0 / Double(n), count: n)
var newPR = Array(repeating: 0.0, count: n)
let base = (1.0 - damping) / Double(n)
for _ in 0..<iterations {
// Distribute rank
for i in 0..<n { newPR[i] = base }
for i in 0..<n {
let outs = outEdges[i]
if outs.isEmpty {
// Dangling node: spread evenly
let share = damping * pr[i] / Double(n)
for j in 0..<n { newPR[j] += share }
} else {
let share = damping * pr[i] / Double(outs.count)
for j in outs { newPR[j] += share }
}
}
pr = newPR
}
// Map back to paths
var out: [String: Double] = [:]
for (p, i) in index { out[p] = pr[i] }
return out
}
/// Dependency-aware emission order:
/// If A depends on B, emit B before A. When multiple nodes are available,
/// prefer higher score, then lexicographic path.
static func orderDependencyAware(_ scored: [ScoredFile]) -> [ScoredFile] { /* elided-implemented; lines=58; h=288bf8e07d */ }
}
FILE: Sources/llminty/Rendering.swift

import Foundation
import SwiftParser
import SwiftSyntax
struct RenderedFile {
let relativePath: String
let content: String
}
final class Renderer {
func render(file: ScoredFile, score: Double) throws -> RenderedFile { /* elided-implemented; lines=18; h=ba8766b17e */ }
// MARK: - Text compaction
/// For .text / .unknown: trim trailing spaces per line, collapse runs of blank lines to a single blank.
private func compactText(_ s: String) -> String { /* elided-implemented; lines=17; h=5134bc375d */ }
/// For Swift bodies: a gentle pass that trims trailing spaces and collapses 3+ blank lines to 2.
private func lightlyCondenseWhitespace(_ s: String) -> String { /* elided-implemented; lines=3; h=f8b0859b0c */ }
// MARK: - Swift policies
enum SwiftPolicy {
case keepAllBodiesLightlyCondensed            // s ≥ 0.75
case keepPublicBodiesElideOthers              // 0.50 ≤ s < 0.75
case keepOneBodyPerTypeElideRest              // 0.25 ≤ s < 0.50
case signaturesOnly                           // s < 0.25
}
func policyFor(score: Double) -> SwiftPolicy { /* elided-implemented; lines=5; h=f94cf34ef9 */ }
// MARK: - Swift rendering (mechanical, deterministic elision)
/// Mechanically elide Swift function/initializer/subscript bodies according to policy.
/// Uses SwiftSyntax rewriting to preserve signatures verbatim.
func renderSwift(text: String, policy: SwiftPolicy) throws -> String { /* elided-implemented; lines=106; h=846128b04d */ }
}
extension StringProtocol {
var isNewline : Bool { /* elided-implemented; lines=1; h=894c3f7941 */ }
}
FILE: Sources/llminty/App.swift

import Foundation
enum BuiltInExcludes {
static func defaultPatterns(outputFileName: String) -> [String] { /* elided-implemented; lines=22; h=cf2d87dd7c */ }
}
/// Aggressively trims blank lines for final output while keeping exactly one
/// blank line after each "FILE: " header. Also:
/// - trims trailing spaces,
/// - collapses 3+ newlines to 2 during pre-pass,
/// - removes all other blank-only lines.
/// Returns a string that always ends with a single trailing newline.
func postProcessMinty(_ s: String) -> String { /* elided-implemented; lines=29; h=d5df507979 */ }
public struct LLMintyApp {
public init() { /* empty */ }
public func run() throws { /* elided-implemented; lines=44; h=1822f0f7b1 */ }
}
FILE: Tests/LLMintyTests/GraphCentralityTests.swift

import XCTest
@testable import llminty
final class GraphCentralityTests: XCTestCase {
private func analyzed(_ path: String, deps: [String]) -> AnalyzedFile { /* elided-implemented; lines=12; h=23453d286a */ }
func testDependencyAwareOrder() { /* elided-implemented; lines=9; h=4f347fcc86 */ }
}
FILE: Sources/llminty/JSONReducer.swift

import Foundation
enum JSONReducer {
// Head/Tail sample sizes
private static let head = 3
private static let tail = 2
private static let dictKeep = 6
static func reduceJSONPreservingStructure(text: String) -> String { /* elided-implemented; lines=11; h=f81a23daae */ }
private static func reduce(_ v: Any, seen: Set<ObjectIdentifier>) -> Any { /* elided-implemented; lines=4; h=2551260e4d */ }
private static func reduceArray(_ a: [Any], seen: Set<ObjectIdentifier>) -> Any { /* elided-implemented; lines=9; h=8bb5a4c60f */ }
private static func reduceDict(_ d: [String: Any], seen: Set<ObjectIdentifier>) -> Any { /* elided-implemented; lines=16; h=eaede32b1a */ }
private static func stringify(_ v: Any) -> String { /* elided-implemented; lines=39; h=df827135f6 */ }
private static func escape(_ s: String) -> String { /* elided-implemented; lines=14; h=27686abb69 */ }
}
FILE: Sources/llminty/main.swift

import Foundation
// Top-level entrypoint for the executable target.
// (Do NOT use @main if the module has any other top-level code.)
do {
try LLMintyApp().run()
} catch {
fputs("llminty: \(error.localizedDescription)\n", stderr)
exit(1)
}
FILE: Tests/LLMintyTests/SwiftAnalyzerTests.swift

import XCTest
@testable import llminty
final class SwiftAnalyzerTests: XCTestCase {
func testEntrypointPublicAPIAndRefs() throws { /* elided-implemented; lines=43; h=cee6bbf824 */ }
}
FILE: Tests/LLMintyTests/LLMintyTests.swift

import XCTest
@testable import llminty
final class LLMintyTests: XCTestCase {
// End-to-end: builds a mini project, runs the app, checks minty.txt framing and ignore behavior.
func testEndToEndRunCreatesMintyFile() throws { /* elided-implemented; lines=42; h=1e55f7cd45 */ }
// Compaction policy: keep exactly one blank line after each FILE header, drop others,
// but allow a single terminal blank line (trailing newline in the file).
func testKeepsOneBlankAfterHeadersAndDropsOthers() { /* elided-implemented; lines=51; h=947806ead3 */ }
}
FILE: Tests/LLMintyTests/RenderingTests.swift

import XCTest
@testable import llminty
final class RenderingTests: XCTestCase {
func testPolicyForThresholds() { /* elided-implemented; lines=7; h=5068d2aa2a */ }
func testRenderSwiftElidesNonPublicBodiesUnderPolicy() throws { /* elided-implemented; lines=21; h=f5f8f1ca1a */ }
func testRenderTextCompactsWhitespace() throws { /* elided-implemented; lines=13; h=b99595bb57 */ }
}
FILE: Tests/LLMintyTests/ScoringTests.swift

import XCTest
@testable import llminty
final class ScoringTests: XCTestCase {
func testScoringWeightsAndEntrypointBonus() { /* elided-implemented; lines=32; h=487d54b6ef */ }
}
FILE: Package.resolved

{
"originHash" : "fafcfb29799827807329c51102552f0f529ef7ef4c8dffc7051b9365efb15aa9",
"pins" : [
{
"identity" : "swift-syntax",
"kind" : "remoteSourceControl",
"location" : "https://github.com/swiftlang/swift-syntax.git",
"state" : {
"revision" : "f99ae8aa18f0cf0d53481901f88a0991dc3bd4a2",
"version" : "601.0.1"
}
}
],
"version" : 3
}
FILE: Package.swift

// swift-tools-version: 6.0
import PackageDescription
let package = Package(
name: "LLMinty",
platforms: [
.macOS(.v13)
],
products: [
.executable(name: "llminty", targets: ["llminty"])
],
dependencies: [
// Match your Swift 6.1 toolchain. 601.x == SwiftSyntax for Swift 6.1
.package(url: "https://github.com/swiftlang/swift-syntax.git", exact: "601.0.1")
],
targets: [
.executableTarget(
name: "llminty",
dependencies: [
.product(name: "SwiftParser", package: "swift-syntax"),
.product(name: "SwiftSyntax", package: "swift-syntax")
],
path: "Sources/llminty"
),
.testTarget(
name: "LLMintyTests",
dependencies: ["llminty"],
path: "Tests/LLMintyTests"
)
]
)
FILE: README.md

# LLMinty
Single-command CLI to emit a token-efficient bundle of a Swift repository for LLMs.
- **Command:** `llminty` (no args)
- **Output:** `./minty.txt`
- **Ignore file:** `.mintyignore` (gitignore semantics: globs, `!` negation, `/`-anchored, dir `/` suffix, `#` comments)
- **Deterministic:** Given the same repo & ignore, output is deterministic.
## Install
```bash
git clone <your fork>
cd LLMinty
swift build -c release
cp .build/release/llminty /usr/local/bin/
````
> If SwiftSyntax version mismatches your toolchain, pin `swift-syntax` to your local Swift’s compatible tag.
## Use
```bash
cd /path/to/your/swift/repo
llminty
# -> prints: Created ./minty.txt (<n> files)
```
```
---
### How this satisfies your spec (with your requested customizations)
- **CLI name:** `llminty` (binary); project name **LLMinty**.
- **Output file:** `minty.txt` (at repo root).
- **Ignore file:** `.mintyignore` (gitignore semantics, including `!` re‑include and dir patterns).
- **Built‑in safe excludes:** Implemented in `BuiltInExcludes.swift`, including self‑exclude of `minty.txt`; users can re‑include via negation.
- **High‑level flow:** Implemented end‑to‑end in `App.run()`.
- **Ranking (0–1):** Uses AST/graph‑only signals:
- Fan‑in and PageRank centrality over file dependency graph (`GraphCentrality`).
- Public API surface (public/open, protocols ×2).
- Type/protocol influence (inbound refs to declared types).
- Complexity via cyclomatic proxies (control‑flow nodes, boolean ops).
- Entrypoint indicator (`@main`, SwiftUI `App`, or top‑level code).
- **Rendering (token‑minimized):**
- **Swift:** Always preserves signatures, generics/where clauses, conformances, access modifiers, and imports. Bodies are retained or elided per score thresholds; very long bodies trimmed in place. One‑body‑per‑type enforced where applicable.
- **JSON:** Keeps representative subset, head+tail arrays, with `// trimmed ...` notes; preserves order.
- **Other text/binaries:** Condensed or replaced with compact placeholders with type/size.
- **Ordering:** Dependency‑aware topo order; tie‑break by higher score, then stable path.
- **Deterministic:** Stable scans, stable path sort, deterministic conflict resolution.
- **Performance:** Directory short‑circuiting; 2 MB per‑file cap; binary detection; no traversal outside CWD.
- **Security & Safety:** Never leaves working directory; unknown extensions treated as non‑text.
- **CLI UX:** On success prints **exactly**:
FILE: Tests/LLMintyTests/FileScannerTests.swift

// Tests/LLMintyTests/FileScannerTests.swift
import XCTest
@testable import llminty
final class FileScannerTests: XCTestCase {
func testScanningKindsAndIgnores() throws { /* elided-implemented; lines=42; h=a17f4fd3fb */ }
}
FILE: Tests/LLMintyTests/IgnoreMatcherTests.swift

import XCTest
@testable import llminty
final class IgnoreMatcherTests: XCTestCase {
func testGlobAnchorsAndNegation() throws { /* elided-implemented; lines=31; h=c199d3e332 */ }
}
FILE: Tests/LLMintyTests/JSONReducerTests.swift

import XCTest
@testable import llminty
final class JSONReducerTests: XCTestCase {
func testArrayAndDictReduction() { /* elided-implemented; lines=8; h=c15d740ef1 */ }
func testPassThroughOnInvalidJSON() { /* elided-implemented; lines=4; h=33ddb319e0 */ }
}
FILE: Tests/LLMintyTests/Fixtures/regenerate_contract.json

{ "should_generate": false }
FILE: Tests/LLMintyTests/IgnoreMatcherTests.swift

import XCTest
@testable import llminty
final class IgnoreMatcherTests: XCTestCase {
func testGlobAnchorsAndNegation() throws { ... }
}
FILE: Tests/LLMintyTests/JSONReducerTests.swift

import XCTest
@testable import llminty
// Tiny shim so we always call the reducer via the module namespace.
private func reduceJSON(_ input: String) -> String { ... }
final class JSONReducerTests: XCTestCase {
func testArrayAndDictReduction_addsTrimSentinelsAndCounts() { ... }
func testDictJustOverThreshold_addsSentinel() { ... }
func testNestedCollections_getTrimmedWhereApplicable() { ... }
func testPassThroughOnInvalidJSON() { ... }
func testScalarsAndBooleansPassThrough() { ... }
func testShortCollections_doNotAddSentinels() { ... }
// MARK: - Boundary & selection tests
func testArrayExactlyAtBoundary_isNotTrimmed() { ... }
func testObjectExactlyAtBoundary_isNotTrimmed() { ... }
func testLargeObject_prefersCollectionsBeforeScalars() { ... }
}
